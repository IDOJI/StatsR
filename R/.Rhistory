Results.list$ROAUC = ROAUC.list = Classification___Logistic___Results___Predict___AUROC(Predicted_Probs = Predicted_Probs,
Logistic) %>% suppressWarnings()
#===========================================================================
# return
#===========================================================================
return(Results.list)
}
Classification___Logistic___Results___Coefficients = function(Logistic){
fit = Logistic$Best_Model
#===========================================================================
# glm
#===========================================================================
if("glm" %in% class(fit)){
Logistic$Best_Coef = fit$coefficients
#===========================================================================
# glmnet
#===========================================================================
}else if("glmnet" %in% class(fit)){
# Check if lambda.min is present
if("lambda.min" %in% names(fit)){
# lambda.min exists, use it to extract coefficients
non_zero_coefs = coef(fit, s = Fit$lambda.min)
} else {
# lambda.min does not exist, use the first lambda in the sequence
# Alternatively, you could use a specific lambda value of your choice
non_zero_coefs = coef(fit, s = fit$lambda[1])
}
# Convert to a regular matrix if it is a sparse matrix
if (class(non_zero_coefs) == "dgCMatrix") {
non_zero_coefs_matrix = as.matrix(non_zero_coefs)
} else {
non_zero_coefs_matrix = non_zero_coefs
}
# Extract non-zero coefficients
non_zero_coef_names = rownames(non_zero_coefs_matrix)[non_zero_coefs_matrix[, 1] != 0]
non_zero_coef_values = non_zero_coefs_matrix[non_zero_coefs_matrix[, 1] != 0, 1]
Logistic$Best_Coef = data.frame(names(non_zero_coef_values), non_zero_coef_values %>% unname)
#===========================================================================
# polr
#===========================================================================
}else if(class(fit)=="polr"){
# Intercept
Fit_Intercept = fit$zeta
# Slope
Fit_Slope = -fit$coefficients
# SE
Fit_deviance = fit$deviance
fit
# Combined
Fit_Coef = c(Fit_Intercept, Fit_Slope)
Fit_Coef = data.frame(Coef = names(Fit_Coef), value = Fit_Coef)
rownames(Fit_Coef) = NULL
Logistic$Best_Coef = Fit_Coef
#===========================================================================
# Ordinal Net
#===========================================================================
}else if(class(fit) == "ordinalNet"){
Fit_Coef = fit$coefs
which_intercepts = grep("Intercept", colnames(Fit_Coef))
# Intercept
Fit_Intercept = Fit_Coef[, which_intercepts] %>% unlist
# Slope
Fit_Slope = Fit_Coef[,-which_intercepts] %>% unlist
# Combined
Fit_Coef = data.frame(Coef = colnames(Fit_Coef), Values = Fit_Coef %>% as.vector)
Fit_Coef = Fit_Coef %>% filter(Values!=0)
Logistic$Best_Coef = Fit_Coef
}
# Combine as a list
# Fit_Coef = list(Intercept = Fit_Intercept, Slope = Fit_Slope[Fit_Slope!=0], Combined = Fit_Coef)
return(Logistic)
}
Logistic = Classification___Logistic___Results___Coefficients(Logistic)
Logistic$Best_Coef
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
table(Combined_y)
Combined_X = rbind(Logistic$Train_X, Logistic$Test_X)
Combined_y = rbind(Logistic$Train_y, Logistic$Test_y)
sub = read.csv("/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Exported/Final/[Final_Selected]_Subjects_list.csv")
sub$ADAS___TOTSCORE
sub$ADAS___TOTSCORE %>% table
sub$ADAS___TOTSCORE %>% length
sub$ADAS___TOTSCORE %>% is.na %>% sum
sub$ADAS___TOTAL13 %>% is.na %>% sum
Combined_X = rbind(Logistic$Train_X, Logistic$Test_X)
Combined_X
Combined_X %>% class
Combined_X %>% colnames
Combined_X %>% colnames %>% head
Combined_X = rbind(Logistic$Train_X, Logistic$Test_X)[,-5]
Combined_X %>% colnames %>% head
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
Logistic$penalty_factor = c(rep(0, 5) , rep(1, n_Vars-5))
colnames(Combined_X) %>% head(10)
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
library(glmnet)
library(pROC)
# Generate predicted probabilities for the validation set
predicted_probabilities <- predict(Logistic$Best_Model, newx = Combined_X, type = "response", s = Logistic$penalty_lambda[40])
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
# If you want to plot the ROC curve
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
RS.fMRI_0_Data.Dictionary(colname = "COT4TOTL", path_Data.Dic = "/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Exported/기타/ADNI_data_dictionary.csv")
RS.fMRI_0_Data.Dictionary(colname = "COT4TOTL", path_Data.Dic = "/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Exported/기타/ADNI_data_dictionary.csv")
RS.fMRI_0_Data.Dictionary(colname = "COT4TOTL", path_Data.Dic = "/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Exported/기타/ADNI_data_dictionary.csv") %>% View
RS.fMRI_0_Data.Dictionary("CONMCXLA", "/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Exported/기타/ADNI_data_dictionary.csv")
ADNI1 = read.csv("/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Downloaded/ADAS_ADNI1_21Jun2023.csv")
ADNI2 = read.csv("/Users/Ido/Library/CloudStorage/Dropbox/Data/ADNI___RS.fMRI___Subjects.Lists/Subjects_Lists_Downloaded/ADAS_ADNIGO23_25Jun2023.csv")
ADNI1$CONMCXLC
ADNI1 %>% View
ADNI1$CONMCXLA
ADNI1$CONMCXLA %>% hist
ADNI2$TOTSCORE %>% hist
ADNI2$TOTSCORE %>% max
ADNI2$TOTSCORE %>% max(na.rm=T)
ADNI2$TOTAL13 %>% hist
RS.fMRI_0_Data.Dictionary = function(colname, path_Data.Dic =  "C:/Users/lleii/Dropbox/Github/Papers___Data/Papers___Data___ADNI___RS.fMRI___Subjects.Lists/___Subjects_Lists_Downloaded/ADNI_data_dictionary.csv"){
# install_package("Hmisc")
# install.packages("C:/Users/lleii/Dropbox/Github/Rpkgs/ADNIprep/ADNIMERGE/ADNIMERGE_0.0.1.tar.gz", repose = NULL, type="source")
# install.packages("/Users/Ido/Library/CloudStorage/Dropbox/Github/Rpkgs/ADNIprep/ADNIMERGE/ADNIMERGE_0.0.1.tar.gz")
# require(ADNIMERGE)
dic = read.csv(path_Data.Dic)
colname = toupper(colname)
selected_col = dic %>% filter(FLDNAME == colname)
if(nrow(selected_col)>0){
return(selected_col)
}else{
cat("\n", crayon::red("There is no such colname!"),"\n")
}
}
colnames(Combined_X) %>% head(10)
Combined_y
Logistic$penalty_factor = c(rep(0, 5) , rep(1, n_Vars-5))
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
Logistic$penalty_factor
Combined_X = rbind(Logistic$Train_X, Logistic$Test_X)[,-5]
Combined_y = rbind(Logistic$Train_y, Logistic$Test_y)
colnames(Combined_X) %>% head(10)
Logistic$penalty_factor = c(rep(0, 5) , rep(1, n_Vars-5))
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
Logistic$Family
Logistic$penalty_factor
colnames(Combined_X) %>% head(5)
colnames(Combined_X) %>% head(6)
colnames(Combined_X) %>% head(5)
Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
length(Logistic$penalty_factor)
dim(Combined_X)
Logistic$penalty_factor = c(rep(0, 5) , rep(1, n_Vars-6))
length(Logistic$penalty_factor)
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[40],
penalty.factor = Logistic$penalty_factor)
# Generate predicted probabilities for the validation set
predicted_probabilities <- predict(Logistic$Best_Model, newx = Combined_X, type = "response", s = Logistic$penalty_lambda[40])
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
# If you want to plot the ROC curve
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
#=============================================================================
# Extracting Results
#=============================================================================
Logistic = Classification___Logistic___Results___Coefficients(Logistic)
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 0.5,
lambda = Logistic$penalty_lambda[50],
penalty.factor = Logistic$penalty_factor)
# Generate predicted probabilities for the validation set
predicted_probabilities <- predict(Logistic$Best_Model, newx = Combined_X, type = "response", s = Logistic$penalty_lambda[40])
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 1,
lambda = Logistic$penalty_lambda[50],
penalty.factor = Logistic$penalty_factor)
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
library(glmnet)
library(pROC)
# Generate predicted probabilities for the validation set
predicted_probabilities <- predict(Logistic$Best_Model, newx = Combined_X, type = "response", s = Logistic$penalty_lambda[40])
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
# If you want to plot the ROC curve
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
# Test
Logistic$Best_Model = Fit = glmnet(x = Combined_X,
y = Combined_y %>% unlist,
family = Logistic$Family,
alpha = 1,
lambda = Logistic$penalty_lambda[30],
penalty.factor = Logistic$penalty_factor)
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
library(glmnet)
library(pROC)
# Generate predicted probabilities for the validation set
predicted_probabilities <- predict(Logistic$Best_Model, newx = Combined_X, type = "response", s = Logistic$penalty_lambda[40])
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
# If you want to plot the ROC curve
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
write.csv(Logistic$Best_Coef, file = paste0(Logistic$path_Export, "/coef.csv"))
Combined_X = rbind(Logistic$Train_X, Logistic$Test_X)[,-5]
Combined_y = rbind(Logistic$Train_y, Logistic$Test_y)
colnames(Combined_X) %>% head(5)
Logistic$penalty_factor = c(rep(0, 5) , rep(1, n_Vars-6))
Combined_X[,1:5]
Combined_X[,1:5] %>% head
Combined_X_new = Combined_X[,1:5]
test = glmnet(x = Combined_X_new, y = Combined_y, family = "binomial")
test = glmnet(x = Combined_X_new, y = Combined_y %>% unlist, family = "binomial")
library(glmnet)
library(pROC)
# Generate predicted probabilities for the test set
predicted_probabilities <- predict(test, newx = test_X, type = "response")
# Generate predicted probabilities for the test set
predicted_probabilities <- predict(test, newx = Combined_X_new, type = "response")
# The predicted_probabilities are a matrix. For binomial, glmnet returns a two-column matrix
# with the first column being the "0" class and the second being the "1" class
# We will use the second column (the "1" class probabilities)
predicted_probabilities <- predicted_probabilities[, 2]
# Compute the AUC using pROC
roc_obj <- roc(Combined_y, predicted_probabilities)
# Compute the AUC using pROC
roc_obj <- roc(Combined_y %>% unlist, predicted_probabilities)
auc_value <- auc(roc_obj)
print(auc_value)
# Plot the ROC curve
plot(roc_obj, main = sprintf("ROC Curve (AUC = %.2f)", auc_value))
test = glmnet(x = Combined_X_new, y = Combined_y %>% unlist, family = "binomial")
# Generate predicted probabilities for the test set
predicted_probabilities <- predict(test, newx = Combined_X_new, type = "response")
predicted_probabilities
head(predicted_probabilities)
dim(predicted_probabilities)
dim(predicted_probabilities)
predicted_probabilities <- predict(test, newx = Combined_X_new, type = "response")
predicted_probabilities
Logistic$Best_Model  = test
#=============================================================================
# Extracting Results
#=============================================================================
Logistic = Classification___Logistic___Results___Coefficients(Logistic)
Logistic$Best_Model
#=============================================================================
# Data combining
#=============================================================================
Binded_Data = dplyr::bind_cols(Logistic$Train_y, Logistic$Train_X)
Binded_Data = Combined_X[,1:5]
Binded_Data = dplyr::bind_cols(Combined_X[,1:5], Combined_y)
Binded_Data
Formula = SUB___as.formula(y = Combined_y %>% names,
x = Combined_X[,1:5] %>% colnames)
Logistic$Best_Model = glm(Formula, data = Binded_Data, family = "binomial")
#=============================================================================
# Results
#=============================================================================
Results = Classification___Logistic___Results(Logistic)
Logistic$Test_y = Combined_y
Logistic$Test_X = Combined_X[,1:5]
#=============================================================================
# Results
#=============================================================================
Results = Classification___Logistic___Results(Logistic)
dim(Combined_y)
dim(Combined_X[,1:5])
Classification___Logistic___Binomial___MLE = function(Logistic){
#=============================================================================
# Data combining
#=============================================================================
Binded_Data = dplyr::bind_cols(Logistic$Train_y, Logistic$Train_X)
#=============================================================================
# Fit proportional odds model
#=============================================================================
Formula = SUB___as.formula(y = Logistic$Train_y %>% names,
x = Logistic$Train_X %>% names)
Logistic$Best_Model = glm(Formula, data = Binded_Data, family = "binomial")
#=============================================================================
# Results
#=============================================================================
Results = Classification___Logistic___Results(Logistic)
return(Results)
}
#=============================================================================
# Extracting Results
#=============================================================================
Logistic = Classification___Logistic___Results___Coefficients(Logistic)
Logistic
#=============================================================================
# Prediction
#=============================================================================
Logistic$Prediction = Classification___Logistic___Results___Predict(Logistic)
#===========================================================================
# Arguments
#===========================================================================
fit = Logistic$Best_Model
Test_X = Logistic$Test_X
Test_y = Logistic$Test_y
Levels = Test_y %>% unlist %>% levels
Levels
length(Test_y)
dim(Test_y)
x_varname = Logistic$Plot_x_varname
y_varname = Logistic$Plot_y_varname
AUC_in_Legend = Logistic$AUC_in_Legend
path_Export = Logistic$path_Export
Results.list = list()
redicted_Probs = predict(fit, newdata = Test_X %>% as.data.frame, type = "response")
Predicted_Probs = predict(fit, newdata = Test_X %>% as.data.frame, type = "response")
Predicted_Probs
Extracted_ROC.list = Classification___Logistic___Results___Predict___AUROC___Binary(Predicted_Probs, Logistic$Test_y, Categories)
# Assuming you have a data frame `data` with predictor variables and a binary outcome `response`
# Fit the logistic model
# Calculate the AUC
roc_obj <- roc(Logistic$Test_y %>% unlist, Predicted_Probs)
auc_value <- auc(roc_obj)
auc_value
# ROC 커브와 AUC 값 출력
png(filename = paste0(Logistic$path_Export, "/AUC.png"))
plot(roc_obj, main = paste("ROC curve (AUC = ", auc_value, ")", sep = ""))
dev.off()
Classification___Logistic___Results___Predict___AUROC___Binary = function(Predicted_Probs, Logistic, Categories){
library(pROC)
# Assuming you have a data frame `data` with predictor variables and a binary outcome `response`
# Fit the logistic model
# Calculate the AUC
roc_obj <- roc(Logistic$Test_y %>% unlist, Predicted_Probs)
auc_value <- auc(roc_obj)
# ROC 커브와 AUC 값 출력
png(filename = paste0(Logistic$path_Export, "/AUC.png"))
plot(roc_obj, main = paste("ROC curve (AUC = ", auc_value, ")", sep = ""))
dev.off()
return(auc_value)
}
Classification___Logistic___Results___Predict___AUROC = function(Predicted_Probs, Logistic){
#=============================================================================
# pacakges
#=============================================================================
install_packages(c("pROC", "ggplot2", "dplyr", "ROCR", "caTools"), load = TRUE)
#=============================================================================
# Computing ROC
#=============================================================================
# Categories
Categories = levels(y_Test_unlist)
if(length(Categories) > 2){
Extracted_ROC.list = Classification___Logistic___Results___Predict___AUROC___Multi(Predicted_Probs, Logistic$Test_y, Categories)
if(!is.null(path_Export)){
ggsave(filename = paste0(path_Export, "/ROC_plot.png"), plot = Extracted_ROC.list$p, width = 10, height = 8, dpi = 300, bg  = "white")
}
}else{
Extracted_ROC.list = Classification___Logistic___Results___Predict___AUROC___Binary(Predicted_Probs, Logistic$Test_y, Categories)
}
#=============================================================================
# Returning results
#=============================================================================
Extracted_ROC.list %>% return()
}
# rm(list=ls())
#=============================================================================================
# Mac
#=============================================================================================
# path_OS = "/Users/Ido/"
#============================================================================================
# Windows
#============================================================================================
# path_OS = "C:/Users/lleii/"
#============================================================================================
require(tidyverse)
require(dplyr)
require(clipr)
require(fda)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/ADNIprep/R"), full.names = T) %>% walk(source)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/StatsR/R"), full.names = T) %>% walk(source)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/refineR/R"), full.names = T) %>% walk(source)
rm(list=ls())
path_OS = "/Users/Ido/"
# rm(list=ls())
#=============================================================================================
# Mac
#=============================================================================================
# path_OS = "/Users/Ido/"
#============================================================================================
# Windows
#============================================================================================
# path_OS = "C:/Users/lleii/"
#============================================================================================
require(tidyverse)
require(dplyr)
require(clipr)
require(fda)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/ADNIprep/R"), full.names = T) %>% walk(source)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/StatsR/R"), full.names = T) %>% walk(source)
list.files(paste0(path_OS, "Dropbox/Github/Rpkgs/refineR/R"), full.names = T) %>% walk(source)
#===============================================================================
# Path
#===============================================================================
path_Data_SB_FDA = paste0(path_OS, "Dropbox/Data/ADNI___RS.fMRI___SB___Functional.Data")
path_Data_SB_FDA_Euclidean = list.files(path_Data_SB_FDA, full.names = T, pattern = "Euclidean")
path_Data_SB_FDA_Euclidean_Smoothing = list.files(path_Data_SB_FDA_Euclidean, full.names=T, pattern = "Smoothing") %>% list.files(full.names=T, pattern = "\\.rds$")
path_Data_SB_FDA_Euclidean__FPCA = paste0(path_Data_SB_FDA_Euclidean, "/FPCA")
path_Data_SB_FDA_Euclidean__FPCA_Scores = paste0(path_Data_SB_FDA_Euclidean, "/FPCA_Scores_With_Group_Nums")
#===============================================================================
# Loading smoothing Data
#===============================================================================
Smoothing.list = lapply(path_Data_SB_FDA_Euclidean_Smoothing, readRDS) %>% setNames( basename(path_Data_SB_FDA_Euclidean_Smoothing) %>% tools::file_path_sans_ext())
k=1
i=1
kth_Smoothing = Smoothing.list[[k]]
kth_Regions = names(kth_Smoothing)
seq_along(kth_Smoothing)
fdobj = kth_Smoothing[[i]]$smoothing$fd
fdobj
threshold = 0.9
path_Export = paste0(path_Data_SB_FDA_Euclidean__FPCA, "/", basename(path_Data_SB_FDA_Euclidean_Smoothing)[k] %>% tools::file_path_sans_ext())
path_Export
file.name = kth_Regions[i]
#=============================================================================
# Fitting & Exporting by Optimal nharm
#=============================================================================
fPCA_Results = FDA___fPCA___Optimal.nharm.by.Threshold(fdobj, threshold, path_Export, file.name)
fPCA_Results$scores
#=============================================================================
# Extract Sample ID
#=============================================================================
ID = fdobj$coefs %>% colnames
#=============================================================================
# fPCA by threshold
#=============================================================================
# init values
nharm = 0
cumulative_var = 0
# increase nharm
nharm = nharm + 1
# pca.fd
fPCA_results = pca.fd(fdobj = fdobj, nharm = nharm)
fPCA_results$varprop
fPCA_results$scores
#=============================================================================
# fPCA by threshold
#=============================================================================
# init values
nharm = 0
cumulative_var = 0
while(cumulative_var < threshold){
# increase nharm
nharm = nharm + 1
# pca.fd
fPCA_results = pca.fd(fdobj = fdobj, nharm = nharm)
# varprop
cumulative_var = fPCA_results$varprop %>% sum
}
?fda.usc::fpc
?fda.usc::fpc
?fda.usc::fpc
path_FPCA_RDS = list.files(path_Data_SB_FDA_Euclidean__FPCA, pattern = "\\.rds$", full.names=T)
FPCA.list = lapply(path_FPCA_RDS, readRDS)
names(FPCA.list) = basename(path_FPCA_RDS) %>% tools::file_path_sans_ext()
FPCA.list$FPCA___FunImgARCWSF___Subjects_ADCN_NA$ACC_pre_L$harmonics
plot(FPCA.list$FPCA___FunImgARCWSF___Subjects_ADCN_NA$ACC_pre_L$harmonics)
?fda::predict.fd
